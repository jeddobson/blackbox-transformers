{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6532e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook shows next token prediction for a transformer. It contains \n",
    "# several prompts that demonstrate interesting features of these pre-trained\n",
    "# models. This example uses the relatively tiny GPT2.\n",
    "\n",
    "# This notebook supports the publication of James E. Dobson, \"On Reading and \n",
    "# Interpreting Black Box Deep Neural Networks,\" International Journal\n",
    "# of Digital Humanities (2023). https://doi.org/10.1007/s42803-023-00075-w\n",
    "#\n",
    "# James E. Dobson\n",
    "# Dartmouth College\n",
    "# https://jeddobson.github.io/\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from typing import List, Optional\n",
    "\n",
    "import matplotlib\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab0caa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n"
     ]
    }
   ],
   "source": [
    "# load GPT2 model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", \n",
    "                                             output_attentions = True,\n",
    "                                             low_cpu_mem_usage = True)\n",
    "tok = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# end of sentence/text token padding\n",
    "tok.pad_token = tok.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "239f11fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_model():\n",
    "    config = model.config.__dict__\n",
    "    print(\"Model type: {0} ({1})\".format(config['model_type'],\n",
    "                                         ' '.join(config['architectures'])))\n",
    "    print(\"Vocab size: {0}\".format(config['vocab_size']))\n",
    "    print(\"Layers: {0}\".format(config['n_layer']))\n",
    "    print(\"Embedding width: {0}\".format(config['n_embd']))\n",
    "    print(\"Parameters:\\n Output Attentions: {0}\\n Output Hidden States: {1}\"\n",
    "          .format(config['output_attentions'],\n",
    "                 config['output_hidden_states']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eee7368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: gpt2 (GPT2LMHeadModel)\n",
      "Vocab size: 50257\n",
      "Layers: 12\n",
      "Embedding width: 768\n",
      "Parameters:\n",
      " Output Attentions: True\n",
      " Output Hidden States: False\n"
     ]
    }
   ],
   "source": [
    "describe_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb1148ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_word_prediction_probs(prompt,n=10):\n",
    "    inp_tok = tok(prompt, \n",
    "              padding=True, \n",
    "              return_tensors=\"pt\").to(\n",
    "    next(model.parameters()\n",
    "        ).device)\n",
    "    input_ids = inp_tok[\"input_ids\"]\n",
    "\n",
    "    # obtain logits\n",
    "    logits = model(**inp_tok).logits[:, -1, :]\n",
    "    \n",
    "    # display top five sorted matches for next token prediction w/ logits probabilities\n",
    "    vals = [[tok.decode(tk.item()),\n",
    "             logits[0][tk.item()].tolist()] for tk in torch.argsort(logits,descending=True)[:, :n][0]]\n",
    "    # display rounded values for next predicted token\n",
    "    \n",
    "    for t,v in vals:\n",
    "        print(t,np.round(v,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04d88e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " English -79.85223\n",
      " political -80.11236\n",
      " social -80.33092\n",
      " psychology -80.34305\n",
      " business -80.51772\n",
      " economics -80.52468\n",
      " environmental -80.56619\n",
      " public -80.56715\n",
      " sociology -80.76482\n",
      " computer -80.78678\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs('Dartmouth College, where she graduated last year with a degree in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f25947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " English -79.67777\n",
      " political -79.78294\n",
      " economics -79.78577\n",
      " business -80.1396\n",
      " computer -80.21712\n",
      " psychology -80.23212\n",
      " chemistry -80.53219\n",
      " public -80.54495\n",
      " environmental -80.56481\n",
      " history -80.57666\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs('Dartmouth College, where he graduated last year with a degree in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6541b81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " psychology -79.46592\n",
      " political -79.49993\n",
      " social -79.51651\n",
      " English -79.58015\n",
      " economics -79.80403\n",
      " sociology -79.87824\n",
      " environmental -79.89843\n",
      " public -79.97591\n",
      " international -79.99066\n",
      " computer -80.05216\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs('Stanford University, where she graduated last year with a degree in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae63a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " economics -79.40723\n",
      " political -79.60328\n",
      " English -79.78493\n",
      " psychology -79.86195\n",
      " computer -79.87939\n",
      " international -80.18056\n",
      " social -80.28078\n",
      " sociology -80.32674\n",
      " biology -80.33907\n",
      " history -80.34368\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs('Stanford University, where he graduated last year with a degree in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e0fecd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " negative -99.20782\n",
      " pain -99.58512\n",
      " stress -99.69791\n",
      " of -99.72576\n",
      " anxiety -99.73475\n",
      " discrimination -99.85999\n",
      " mental -100.48582\n",
      " racial -100.50221\n",
      " than -100.51519\n",
      " severe -100.66917\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs(\"Typically white people experience more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ba7f25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " discrimination -98.85595\n",
      " violence -99.16276\n",
      " of -99.36404\n",
      " negative -99.62209\n",
      " pain -99.7808\n",
      " stress -99.78352\n",
      " racism -99.96166\n",
      " racial -99.97469\n",
      " poverty -100.08421\n",
      " anxiety -100.08694\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs(\"Typically Black people experience more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ba1d95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the -83.17813\n",
      " he -84.3437\n",
      " his -84.63093\n",
      " she -84.99335\n",
      " if -85.17799\n",
      " her -85.27285\n",
      " there -85.31738\n",
      " it -85.399\n",
      " a -85.4878\n",
      " this -85.76642\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs(\"The doctor was concerned that\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce1884ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the -87.40051\n",
      " this -87.91363\n",
      " her -88.77174\n",
      " a -89.59035\n",
      " that -89.78563\n",
      " psychology -89.91816\n",
      " it -90.12193\n",
      " both -90.36841\n",
      " mathematics -90.52245\n",
      " biology -90.52323\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs(\"The professor was a specialist in this narrow area, she had years of preparation in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d885432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the -87.34089\n",
      " this -87.79362\n",
      " his -89.33225\n",
      " a -89.5732\n",
      " it -89.90223\n",
      " that -89.92577\n",
      " psychology -89.95166\n",
      " mathematics -90.19899\n",
      " both -90.3168\n",
      " physics -90.40037\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs(\"The professor was a specialist in this narrow area, he had years of preparation in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fe7739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " he -115.80422\n",
      " the -116.07866\n",
      " she -116.24413\n",
      " was -116.89723\n",
      " it -117.17738\n",
      " his -117.28649\n",
      " when -117.34982\n",
      " had -117.59496\n",
      " her -117.76831\n",
      " after -117.82028\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs(\"The worker was unprepared and had never performed this task before, but\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7dc577d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " he -112.64876\n",
      " the -113.13715\n",
      " she -113.5186\n",
      " his -113.86226\n",
      " was -114.06367\n",
      " when -114.16415\n",
      " it -114.37943\n",
      " after -114.62242\n",
      " had -114.78773\n",
      " her -114.85073\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs(\"The construction worker was unprepared and had never performed this task before, but\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15a44ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " she -115.26384\n",
      " the -116.01732\n",
      " he -116.21288\n",
      " her -116.67821\n",
      " when -116.72872\n",
      " it -116.86908\n",
      " was -116.90417\n",
      " after -117.45573\n",
      " his -117.66711\n",
      " had -117.67586\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs(\"The dancer was unprepared and had never performed this task before, but\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daabc473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " he -114.65598\n",
      " the -115.14966\n",
      " she -115.26196\n",
      " when -115.37276\n",
      " it -115.944\n",
      " was -116.41553\n",
      " then -116.50826\n",
      " that -116.54526\n",
      " his -116.73866\n",
      " said -116.90041\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs(\"The bank teller was sure that the deposit was correct, but\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17540a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " he -114.36736\n",
      " she -115.23783\n",
      " the -115.57484\n",
      " it -116.13039\n",
      " when -116.27366\n",
      " his -116.61208\n",
      " that -116.69053\n",
      " then -116.78804\n",
      " was -117.11881\n",
      " said -117.14942\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs(\"The lawyer was sure that the argument was correct, but\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15b4a1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " he -129.33742\n",
      " it -130.17656\n",
      " had -130.20757\n",
      " the -130.65405\n",
      " his -130.76155\n",
      " was -130.87242\n",
      " she -130.91708\n",
      " when -131.29041\n",
      " never -131.47581\n",
      " in -131.56242\n"
     ]
    }
   ],
   "source": [
    "next_word_prediction_probs(\"The programmer had prepared and studied this topic at college, but\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
